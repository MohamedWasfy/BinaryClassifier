{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BinaryClassifier",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNNu3t7EXwV7F73fcNFaTff",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohamedWasfy/BinaryClassifier/blob/master/BinaryClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQzdwRzViVD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn import metrics"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBrm0ghzjS4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#loading training data\n",
        "#name = ['variable1','variable2','variable3','variable4','variable5','variable6','variable7','variable8','variable9','variable10','variable11','variable12','variable13','variable14','variable15','variable16','variable17','variable18','variable19','classLabel']\n",
        "training_data = pd.read_csv('/content/training.csv',sep=';')\n",
        "training_data.head()\n",
        "# dropping variable 18 column as it is mostly NAN value so it does not has mucs information gain\n",
        "training_data.drop('variable18', axis=1, inplace=True)\n",
        "# cleaning data from rows that has NAN values\n",
        "training_data.replace('','NAN',inplace=True)\n",
        "training_data.dropna(inplace=True)\n",
        "#extracting labels and roping them from the training_data dataframe\n",
        "training_labels = training_data['classLabel']\n",
        "training_data.drop('classLabel', axis=1, inplace=True)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDvOn77e2BPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#loading test data\n",
        "test_data = pd.read_csv('/content/validation.csv',sep=';')\n",
        "test_data.head()\n",
        "# dropping variable 18 column as it is mostly NAN value so it does not has mucs information gain\n",
        "test_data.drop('variable18', axis=1, inplace=True)\n",
        "# cleaning data from rows that has NAN values\n",
        "test_data.replace('','NAN',inplace=True)\n",
        "test_data.dropna(inplace=True)\n",
        "#extracting labels and roping them from the training_data dataframe\n",
        "test_labels = test_data['classLabel']\n",
        "test_data.drop('classLabel', axis=1, inplace=True)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6wSk__hFtF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#extracting numrecal fetures from categorical for normalizatio\n",
        "numeric_cols= ['variable2','variable3','variable8','variable11','variable14','variable15','variable17']\n",
        "Str_to_num_cols=['variable2','variable3','variable8']\n",
        "num_train_subset= training_data[numeric_cols]\n",
        "#num_train_subset= pd.DataFrame(num_train_subset, dtype='float')\n",
        "num_test_subset= test_data[numeric_cols]\n",
        "\n",
        "for col in Str_to_num_cols:\n",
        "  num_train_subset[col]=num_train_subset[col].apply(lambda x: x.replace(',','.'))\n",
        "  num_train_subset[col] = pd.to_numeric(num_train_subset[col],downcast='float')\n",
        "  num_test_subset[col]=num_test_subset[col].apply(lambda x: x.replace(',','.'))\n",
        "  num_test_subset[col] = pd.to_numeric(num_test_subset[col],downcast='float')\n",
        "\n",
        "\n",
        "#extracting categorical subset of data for one-hot-enconding\n",
        "cat_columns=['variable1','variable4','variable5','variable6','variable7','variable9','variable10','variable12','variable13']\n",
        "cat_train_subset= training_data[cat_columns]    \n",
        "cat_test_subset= test_data[cat_columns]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGv6K1dDlYHe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#feature scaling and normalization\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler()\n",
        "num_train_subset = sc_X.fit_transform(num_train_subset)\n",
        "num_test_subset = sc_X.transform(num_test_subset)\n",
        "\n",
        "# one-hot-encoding for categorical data\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "OHE=OneHotEncoder()\n",
        "cat_train_OHE = OHE.fit_transform(cat_train_subset).toarray()\n",
        "cat_test_OHE = OHE.transform(cat_test_subset).toarray()\n",
        "\n",
        "\n",
        "#concatinating both cateegorica data and numerical data \n",
        "X_train = np.concatenate((num_train_subset,cat_train_OHE), axis=1)\n",
        "X_test = np.concatenate((num_test_subset,cat_test_OHE),axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aefTJX5bwIi3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "4ea95b83-aa6d-4cc4-c8cf-d577418928ef"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "classifier = DecisionTreeClassifier(criterion='entropy',max_features=40,class_weight='balanced')\n",
        "classifier = classifier.fit(X_train,training_labels)\n",
        "\n",
        "\n",
        "#prediction\n",
        "y_pred = classifier.predict(X_test)#Accuracy\n",
        "print(classification_report(test_labels.to_numpy(), y_pred))\n",
        "\n",
        "print('Accuracy Score:', metrics.accuracy_score(test_labels,y_pred))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         no.       0.83      0.82      0.82        99\n",
            "        yes.       0.81      0.82      0.81        92\n",
            "\n",
            "    accuracy                           0.82       191\n",
            "   macro avg       0.82      0.82      0.82       191\n",
            "weighted avg       0.82      0.82      0.82       191\n",
            "\n",
            "Accuracy Score: 0.8167539267015707\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLGfT8qTC3Ip",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "9f2cf18d-eaa5-4b9f-a03f-b8f46271f4f9"
      },
      "source": [
        "from sklearn import svm\n",
        "clf = svm.SVC(class_weight='balanced')\n",
        "clf.fit(X_train, training_labels.to_numpy())\n",
        "\n",
        "y_pred=clf.predict(X_test)\n",
        "print(classification_report(test_labels.to_numpy(), y_pred)) \n",
        "\n",
        "print('Accuracy Score:', metrics.accuracy_score(test_labels,y_pred))\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         no.       0.86      0.82      0.84        99\n",
            "        yes.       0.81      0.86      0.84        92\n",
            "\n",
            "    accuracy                           0.84       191\n",
            "   macro avg       0.84      0.84      0.84       191\n",
            "weighted avg       0.84      0.84      0.84       191\n",
            "\n",
            "Accuracy Score: 0.837696335078534\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}